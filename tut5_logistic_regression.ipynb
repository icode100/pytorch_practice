{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOvjzYUTRm7uWTQPFHUe4Uj"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["---\n","\n","We follow the same pipeline\n","\n","---\n","\n","training pipeline in pytorch\n","* Design model(input,output size, forward pass)\n","* Construct loss and optimizer\n","* Training loop\n","    * forward pass: compute prediction\n","    * backward pass: gradients\n","    * update weights\n","\n","We are here doing binary classification:\n","equations are as follows:\n","\n","$ z = x.w+b $, this is same as the linear regression layer\\\n","$ \\hat{y} = σ(z) $\\\n","where, $σ = \\frac{1}{1+e^{-z}}$"],"metadata":{"id":"MQEgWMFFlolB"}},{"cell_type":"code","execution_count":20,"metadata":{"id":"tCPi6CjrPu2d","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1709392618672,"user_tz":-330,"elapsed":894,"user":{"displayName":"Ipsit Das","userId":"05027171651305250694"}},"outputId":"65f915e2-1825-4927-f423-b5179353474d"},"outputs":[{"output_type":"stream","name":"stdout","text":["epoch:10, loss = 0.3733\n","epoch:20, loss = 0.2366\n","epoch:30, loss = 0.1752\n","epoch:40, loss = 0.1431\n","epoch:50, loss = 0.1239\n","epoch:60, loss = 0.1109\n","epoch:70, loss = 0.1013\n","epoch:80, loss = 0.0939\n","epoch:90, loss = 0.0880\n","epoch:100, loss = 0.0830\n","accuracy = 0.9298\n"]}],"source":["import torch\n","import torch.nn as nn\n","from sklearn import datasets\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.model_selection import train_test_split\n","import numpy as np\n","\n","# prepare data\n","bc = datasets.load_breast_cancer()\n","x,y = bc.data, bc.target\n","n_samples, n_features = x.shape\n","x_train,x_test,y_train,y_test = train_test_split(x,y,test_size = 0.2,random_state = 1234)\n","\n","#scaling\n","n_features\n","sc = StandardScaler()\n","x_train = sc.fit_transform(x_train) # mean = 0 & sd = 1\n","x_test = sc.transform(x_test)\n","x_train = torch.from_numpy(x_train.astype(np.float32))\n","x_test = torch.from_numpy(x_test.astype(np.float32))\n","y_train = torch.from_numpy(y_train.astype(np.float32))\n","y_test = torch.from_numpy(y_test.astype(np.float32))\n","y_train = y_train.view(y_train.shape[0],1)\n","y_test = y_test.view(y_test.shape[0],1)\n","\n","# model\n","class LogisticRegression(nn.Module):\n","    def __init__(self,n_input_features):\n","        super(LogisticRegression, self).__init__()\n","        self.linear = nn.Linear(n_input_features,1)\n","    def forward(self,x):\n","        y_predicted = torch.sigmoid(self.linear(x))\n","        return y_predicted\n","\n","model = LogisticRegression(n_features)\n","\n","# loss and optimizer\n","criterion = nn.BCELoss()\n","optimizer = torch.optim.NAdam(model.parameters(),lr = 0.01)\n","\n","# training loop\n","num_epoch = 100\n","for epoch in range(num_epoch):\n","\n","    # forward pass\n","    y_predicted = model(x_train)\n","\n","    # loss\n","    loss = criterion(y_predicted, y_train)\n","\n","    # backward pass\n","    loss.backward()\n","\n","    # update parameters\n","    optimizer.step()\n","\n","    optimizer.zero_grad()\n","\n","    if (epoch+1)%10==0:\n","        print(f'epoch:{epoch+1}, loss = {loss.item():.4f}')\n","\n","with torch.no_grad():\n","    y_predicted = model(x_test)\n","    y_predicted_class = y_predicted.round()\n","\n","    #accuracy: how many classifications are correct among the total number of classification\n","    acc = y_predicted_class.eq(y_test).sum() / float(y_test.shape[0])\n","    print(f'accuracy = {acc.item():.4f}')\n","\n","\n"]}]}