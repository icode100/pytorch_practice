{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"16pSlDS3yGQ-GR7PatQVnb87qGI9JSFO-","authorship_tag":"ABX9TyMR8Vsg6kaHm/LFvfJiH+dm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["### For large datasets we use batch training\n","---\n","\n","we divide the dataset into batches and we train each individual batch and calculate loss for each batch and update weights correspondingly\n","\n","\n","### some terms\n","\n","\n","---\n","\n","* epoch = one forward and backward pass of **ALL** data points.\n","* batch_size = number of training samples in one forward & backward pass\n","* number of iterations = number of passes, each pass using [batch_size] number of samples\n","\n","e.g. 100 samples, batch_size = 20 â‡’ 100/20 = 5 iterations for each epoch"],"metadata":{"id":"OBRI_dtowEod"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p8-v7Fch8b57","executionInfo":{"status":"ok","timestamp":1709396092079,"user_tz":-330,"elapsed":21968,"user":{"displayName":"Ipsit Das","userId":"05027171651305250694"}},"outputId":"42c2bf0a-90ed-4c8a-a5e7-cd123da36a05"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d2-tHSelwBc4","executionInfo":{"status":"ok","timestamp":1709398035515,"user_tz":-330,"elapsed":1023,"user":{"displayName":"Ipsit Das","userId":"05027171651305250694"}},"outputId":"9480c5e1-306f-43bd-97b8-f4f349f2b877"},"outputs":[{"output_type":"stream","name":"stdout","text":["178 45\n","epoch 1/2, step 5/45, inputs torch.Size([4, 13])\n","epoch 1/2, step 10/45, inputs torch.Size([4, 13])\n","epoch 1/2, step 15/45, inputs torch.Size([4, 13])\n","epoch 1/2, step 20/45, inputs torch.Size([4, 13])\n","epoch 1/2, step 25/45, inputs torch.Size([4, 13])\n","epoch 1/2, step 30/45, inputs torch.Size([4, 13])\n","epoch 1/2, step 35/45, inputs torch.Size([4, 13])\n","epoch 1/2, step 40/45, inputs torch.Size([4, 13])\n","epoch 1/2, step 45/45, inputs torch.Size([2, 13])\n","\n","\n","epoch 2/2, step 5/45, inputs torch.Size([4, 13])\n","epoch 2/2, step 10/45, inputs torch.Size([4, 13])\n","epoch 2/2, step 15/45, inputs torch.Size([4, 13])\n","epoch 2/2, step 20/45, inputs torch.Size([4, 13])\n","epoch 2/2, step 25/45, inputs torch.Size([4, 13])\n","epoch 2/2, step 30/45, inputs torch.Size([4, 13])\n","epoch 2/2, step 35/45, inputs torch.Size([4, 13])\n","epoch 2/2, step 40/45, inputs torch.Size([4, 13])\n","epoch 2/2, step 45/45, inputs torch.Size([2, 13])\n","\n","\n"]}],"source":["import torch\n","import torchvision\n","from torch.utils.data import Dataset, DataLoader\n","import numpy as np\n","import math\n","\n","class WineDataset(Dataset):\n","    def __init__(self):\n","        xy = np.loadtxt('/content/drive/MyDrive/dataML/wine.csv',delimiter = ',',dtype=np.float32,skiprows=1)\n","        self.x = torch.from_numpy(xy[:,1:])\n","        self.y = torch.from_numpy(xy[:,:1])\n","        self.n_samples = xy.shape[0]\n","\n","    def __getitem__(self,index):\n","        return self.x[index],self.y[index]\n","    def __len__(self):\n","        return self.n_samples\n","\n","\n","dataset = WineDataset()\n","# here num_workers mean it will work parallely with 2 threads working together\n","dataloader = DataLoader(dataset = dataset, batch_size = 4, shuffle=True, num_workers = 2)\n","\n","# training loop\n","num_epochs = 2\n","total_samples = len(dataset)\n","n_iterations = math.ceil(total_samples / 4) #num_samples/batch_size\n","print(total_samples, n_iterations)\n","\n","for epoch in range(num_epochs):\n","    for i,(inputs, labels) in enumerate(dataloader):\n","        # forward backward and update\n","        if (i+1)%5 == 0:\n","            print(f'epoch {epoch+1}/{num_epochs}, step {i+1}/{n_iterations}, inputs {inputs.shape}')\n","    print('\\n')\n"]},{"cell_type":"markdown","source":["# Transform methods on dataset\n","\n","\n","---\n","\n","convert the MNIST dataset to tensor using the following\n","--------\n","```python\n","    dataset = torchvision.datasets.MNIST(root = './data',transform = torchvision.transforms.ToTensor())\n","```\n","Transforms can be applied to PIL images, tensors, ndarrays, or custom data\n","during creation of the DataSet\n","\n","complete list of built-in transforms:\n","https://pytorch.org/docs/stable/torchvision/transforms.html\n","\n","On Images\n","---------\n","* CenterCrop, Grayscale, Pad, RandomAffine\n","RandomCrop, RandomHorizontalFlip, RandomRotation\n","Resize, Scale\n","\n","On Tensors\n","----------\n","* LinearTransformation, Normalize, RandomErasing\n","\n","Conversion\n","----------\n","* ToPILImage: from tensor or ndrarray\n","* ToTensor : from numpy.ndarray or PILImage\n","\n","Generic\n","-------\n","Use Lambda\n","\n","Custom\n","------\n","Write own class\n","\n","Compose multiple Transforms\n","---------------------------\n","```python\n","composed = transforms.Compose([Rescale(256),RandomCrop(224)])\n","```"],"metadata":{"id":"n__d-9c8EdBn"}},{"cell_type":"code","source":["class WineDataset(Dataset):\n","    def __init__(self, transform):\n","        xy = np.loadtxt('/content/drive/MyDrive/dataML/wine.csv',delimiter = ',',dtype=np.float32,skiprows=1)\n","        self.x = xy[:,1:]\n","        self.y = xy[:,:1]\n","        self.n_samples = xy.shape[0]\n","        self.transform = transform\n","\n","    def __getitem__(self,index):\n","        sample = self.x[index],self.y[index]\n","        if self.transform:\n","            sample = self.transform(sample)\n","        return sample\n","    def __len__(self):\n","        return self.n_samples\n","\n","class ToTensor:\n","    def __call__(self,sample):\n","        inputs,targets = sample\n","        return torch.from_numpy(inputs),torch.from_numpy(targets)\n","\n","class MulTransform:\n","    def __init__(self,factor):\n","        self.factor = factor\n","\n","    def __call__(self,sample):\n","        inputs, target = sample\n","        inputs *= self.factor\n","        return inputs,target\n","dataset = WineDataset(transform = None)\n","features,lables = dataset[0]\n","print(features)\n","print(type(features), type(lables))\n","print('\\n')\n","# we club up both the transforms in one\n","composed = torchvision.transforms.Compose([ToTensor(),MulTransform(2)])\n","dataset = WineDataset(transform = composed)\n","features,lables = dataset[0]\n","print(features)\n","print(type(features), type(lables))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7REYkONg_KCG","executionInfo":{"status":"ok","timestamp":1709400913846,"user_tz":-330,"elapsed":8,"user":{"displayName":"Ipsit Das","userId":"05027171651305250694"}},"outputId":"ffc2151f-d48a-471a-b5b6-963b261b38ae"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["[1.423e+01 1.710e+00 2.430e+00 1.560e+01 1.270e+02 2.800e+00 3.060e+00\n"," 2.800e-01 2.290e+00 5.640e+00 1.040e+00 3.920e+00 1.065e+03]\n","<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n","\n","\n","tensor([2.8460e+01, 3.4200e+00, 4.8600e+00, 3.1200e+01, 2.5400e+02, 5.6000e+00,\n","        6.1200e+00, 5.6000e-01, 4.5800e+00, 1.1280e+01, 2.0800e+00, 7.8400e+00,\n","        2.1300e+03])\n","<class 'torch.Tensor'> <class 'torch.Tensor'>\n"]}]}]}